
整体架构参考数字人语音对话的流程，简单来说就是 dify 只接收文本内容，然后我们的后端负责接收前端语音文件，给到大模型那边进行语音转文字，然后我们再拿到文本内容调用 dify 接口，把接口内容返回给前端这样。

[[2025-07-08]] ：开发了前后端，前端用的 ts ，妈的，不会，明天改成 js 

明天要完成的工作：

- 前端打包进入后端统一访问
- 后端镜像的构建和部署（参考 GpuStack）

```
npx create-umi .
Need to install the following packages:
create-umi@4.4.11
```

```
docker build -t kn_demo:latest .
```

[[2025-07-09]] 已经完成上述功能啦，哈哈哈哈

下一阶段可以补充一下：

- 压测和单元测试（实在没事干可以玩一下）