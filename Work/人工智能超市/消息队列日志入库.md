---
tags: springboot rocketmq apisix
---

## 概述

我们通过 apisix 的 rocket-logger 插件注册到了所有的路由里面去，这样就使得所有的路由的请求信息我们都可以将其推送到消息队列里面去。

在我们的业务场景中，我们的服务通过 api 提供出去，通过网关 apisix 进行对所有的接口的整合。某个资源的请求次数，请求响应等等信息将作为计费的重要凭据。当然我们不可能在网关层面直接把这些信息写入数据库中，其中的 IO 消耗会严重影响网关转发的性能。所以我们会将这些信息写入消息队列中，然后再维护一个服务对这些消息进行消费，写入数据库中，然后给到计费服务那边去进行计费统计。

![[网关方服务计费流程-Flowchart.svg]]

## 网关写入消息队列

这里我们通过插件 rocketmq-logger 绑定到路由上，以此达到将每个路由的请求信息推送进行消息队列的目的。

更多参数有关的内容我们可以看官方的介绍 [rocketmq-logger](https://apisix.apache.org/docs/apisix/plugins/rocketmq-logger)。这里我们只给出我们的设置：简单来说就是既要请求内容，也要返回内容。

```shell
curl http://127.0.0.1:30015/apisix/admin/routes/llm \
  -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \
  -X PATCH \
  -d '
{
  "plugins": {
    "rocketmq-logger": {
      "nameserver_list": [ "211.90.240.240:30040" ],
      "topic": "test-apisix",
      "include_req_body": true,
      "include_resp_body": true
    }
  }
}'
```

这样我们就给我们这个路由注册了这个插件。

### APISIX 全局注册插件

#### 创建 plugin_config

首先我们需要向 APISIX 注册一个插件配置

```shell
curl http://127.0.0.1:30015/apisix/admin/plugin_configs/1 \
  -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \
  -X PUT \
  -d '
{
  "plugins": {
    "rocketmq-logger": {
      "nameserver_list": ["211.90.240.240:30040"],
      "topic": "test-apisix",
      "include_req_body": true,
      "include_resp_body": true
    }
  }
}'
```

#### 启用 plugin_config 为全局插件

```shell
curl http://127.0.0.1:30015/apisix/admin/global_rules/1 \
  -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \
  -X PUT \
  -d '
{
  "plugins": {
    "plugin-config": {
      "plugin_config_id": 1
    }
  }
}'
```

## 使用 SpringBoot 消费消息

鉴于 rocketmq-client 对 Java 语言的支持性更好，我们使用 java 去写消费者的代码。说到 java 那当然是用 spring 了啦。

rocketmq-spring-boot-starter 是对 rocketmq-client 的二次封装，专门用于在 spring-boot 里面更方便地集成和使用 rocketmq 。

### 消费者初始化

```java
DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup);
consumer.setNamesrvAddr(RocketMQConfig.NAME_SERVER);
consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_TIMESTAMP);
consumer.setConsumeTimestamp("20240101000000");
consumer.subscribe(RocketMQConfig.TOPIC, "*");
```

### 注册并发消息监听器

```java
consumer.registerMessageListener(new MessageListenerConcurrently() { ... });
```

这里使用了并发的消费模式（线程池并发处理消息），每次拉取多条消息，逐条处理

### consumeMessage 方法

我们可以看到：

```java
// Source code is decompiled from a .class file using FernFlower decompiler.
package org.apache.rocketmq.client.consumer.listener;

import java.util.List;
import org.apache.rocketmq.common.message.MessageExt;

public interface MessageListenerConcurrently extends MessageListener {
   ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> var1, ConsumeConcurrentlyContext var2);
}
```

这是一个 **接口方法**，它并没有默认实现，**我们必须实现它（实现=override）**，否则编译器会报错。这个接口的入参如下：

| 参数        | 类型                           | 说明                      |
| --------- | ---------------------------- | ----------------------- |
| `msgs`    | `List<MessageExt>`           | 一批从 Broker 拉取到的消息（可能多条） |
| `context` | `ConsumeConcurrentlyContext` | 上下文对象，包含线程信息、消费位点等      |
通过重写这个方法，我们告诉 RocketMQ ：每次我们把消息推动给这个消费者，我们就会用这个方法来处理消息。在这个方法里面，我们可以：

- 解析消息内容
- 判断消息重复与否
- 执行业务处理（入库、发送通知、写日志）
- 捕获异常并决定是否重试
- 返回消费状态：`CONSUME_SUCCESS` 或 `RECONSUME_LATER`

### 重写方法

虽然 Java 中实现接口的方法时写 `@Override` 不是强制性的，但它非常有用：

|优点|说明|
|---|---|
|编译期检查|方法签名拼错时会报错（防止 Bug）|
|阅读更清晰|明确告诉别人：这个方法是实现自接口|
|推荐写法|是 Java 编码规范中的好习惯|
#### 循环处理消息列表

即使只收到一条消息，RocketMQ 也会以 List 的方式传入，所以必须循环处理。处理过程中每条消息独立完成，不应该因为一条消息的失败而影响其他的消费逻辑。

```java
for(MessageExt message: msgs){
	...
}
```

#### 获取消息唯一标识：防止重复消费

```java
String msgId = message.getMsgId();
```

在 RocketMQ 中每条消息都会自动生成一个全局唯一的 msgId 。

在实际的业务中，为了防止消费者重复消费相同的消息（RocketMQ 会在消费失败的时候自动重发），我们使用 msgId 做 **幂等控制**。

#### 消息内容解析 + 构造入库实体

##### 表结构和实体设计

```sql
CREATE TABLE `mq_consume_log` (
  `id` BIGINT NOT NULL AUTO_INCREMENT COMMENT '主键，自增',
  `msg_id` VARCHAR(64) NOT NULL COMMENT '消息唯一 ID',
  `topic` VARCHAR(128) NOT NULL COMMENT 'RocketMQ Topic',
  `tags` VARCHAR(128) DEFAULT NULL COMMENT '消息标签',
  `message_keys` VARCHAR(128) DEFAULT NULL COMMENT '消息 Key',
  `body` TEXT NOT NULL COMMENT '原始日志 JSON 字符串',
  `route_id` VARCHAR(64) NOT NULL COMMENT 'APISIX 路由 ID',
  `prompt_tokens` INT NOT NULL DEFAULT 0 COMMENT 'OpenAI Prompt Tokens',
  `completion_tokens` INT NOT NULL DEFAULT 0 COMMENT 'OpenAI Completion Tokens',
  `total_tokens` INT NOT NULL DEFAULT 0 COMMENT 'OpenAI Total Tokens',
  `create_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_msg_id` (`msg_id`),
  KEY `idx_route_id` (`route_id`),
  KEY `idx_create_time` (`create_time`)
) ENGINE=InnoDB
  DEFAULT CHARSET=utf8mb4
  COLLATE=utf8mb4_unicode_ci
  COMMENT='消费日志表，含 APISIX 路由和 OpenAI Token 明细';
```

[[计费表表结构]]

```java
package com.jmz.mq2data.model;

import java.time.LocalDateTime;
import lombok.Data;

@Data
public class MqConsumeLog {
    private Long    id;
    private String  msgId;
    private String  topic;
    private String  tags;
    private String  messageKeys;
    private String  body;
    private String  routeId;            
    private Integer promptTokens;       
    private Integer completionTokens;   
    private Integer totalTokens;        
    private LocalDateTime createTime;
}
```

插入语句

```java
@Mapper
public interface MqConsumeLogMapper {
    @Insert("INSERT INTO mq_consume_log "
          + "(msg_id, topic, tags, message_keys, body, "
          + " route_id, prompt_tokens, completion_tokens, total_tokens) "
          + "VALUES (#{msgId}, #{topic}, #{tags}, #{messageKeys}, #{body}, "
          + "#{routeId}, #{promptTokens}, #{completionTokens}, #{totalTokens})")
    int insert(MqConsumeLog log);
}
```

##### 内容解析 + 构造实体

```java
String body = new String(message.getBody(), StandardCharsets.UTF_8);
```

RocketMQ 消息体是 `byte[]`，你需要用合适的编码（这里是 UTF-8）还原成字符串。

```java
String msgId = message.getMsgId();
String body = new String(message.getBody(), StandardCharsets.UTF_8);

try {
    // 1) 先解析最外层 APISIX 日志，支持数组或对象
    Object parsed = JSON.parse(body);
    JSONObject logJson = null;

    if (parsed instanceof JSONArray) {
        JSONArray arr = (JSONArray) parsed;
        if (arr.isEmpty()) {
            log.warn("收到空数组日志，msgId={}", msgId);
            continue;
        }
        logJson = arr.getJSONObject(0);
    } else if (parsed instanceof JSONObject) {
        logJson = (JSONObject) parsed;
    } else {
        log.error("日志格式不是 JSON 对象或数组，msgId={}, body={}", msgId, body);
        continue;
    }

    // 2) 拆出路由 ID
    String routeId = logJson.getString("route_id");

    // 3) 拆出 APISIX response.body（它本身是字符串）
    JSONObject responseJson = logJson.getJSONObject("response");
    String responseBodyStr = responseJson != null
        ? responseJson.getString("body")
        : null;

    // 4) 解析 OpenAI usage，可能为 null
    Integer promptTokens    = null;
    Integer completionTokens= null;
    Integer totalTokens     = null;
    if (responseBodyStr != null) {
        JSONObject aiJson = JSON.parseObject(responseBodyStr);
        JSONObject usage  = aiJson.getJSONObject("usage");
        if (usage != null) {
            promptTokens     = usage.getInteger("prompt_tokens");
            completionTokens = usage.getInteger("completion_tokens");
            totalTokens      = usage.getInteger("total_tokens");
        }
    }

    // 5) 填充实体并入库
    MqConsumeLog logEntity = new MqConsumeLog();
    logEntity.setMsgId(msgId);
    logEntity.setTopic(message.getTopic());
    logEntity.setTags(message.getTags());
    logEntity.setMessageKeys(message.getKeys());
    logEntity.setBody(body);
    logEntity.setRouteId(routeId);
    logEntity.setPromptTokens(promptTokens);
    logEntity.setCompletionTokens(completionTokens);
    logEntity.setTotalTokens(totalTokens);
```

- 构造一个日志实体类，用于后续写入数据库。
- 这一步体现了“**将消息做业务记录**”的目的，比如存档、审计、统计等。

#### 插入数据库 + 幂等处理

```java
logMapper.insert(logEntity);
```

将消费到的消息写入数据库（假设 `msg_id` 是主键或唯一索引）。

```java
} catch (DuplicateKeyException e) {
    log.warn("检测到重复消息 [{}]，已跳过", msgId);
```

- 如果消息重复（即 RocketMQ 重发了相同 `msgId` 的消息），插入操作会触发唯一约束冲突。
- 捕获 `DuplicateKeyException`，记录警告，并 **“跳过不重试”**，是保障幂等性的关键。

为什么不能重试？

> 因为如果这条消息已经成功处理过，再处理一次可能会造成数据污染（比如重复入账、发奖等），所以我们明确判断为“重复消息”，直接跳过。

#### 通用异常处理 + 消息重试机制

```java
} catch (Exception e) {
    log.error("写库异常，msgId={}，稍后重试", msgId, e);
    return ConsumeConcurrentlyStatus.RECONSUME_LATER;
}
```

- 捕获除重复主键外的所有异常，比如数据库超时、连接断开、系统异常等。
- 返回 `RECONSUME_LATER` 给 RocketMQ，表示这条消息**消费失败**，**稍后再试**（RocketMQ 会自动重试）。

[聊聊 rocketmq 的 RECONSUME_LATER](https://cloud.tencent.com/developer/article/1539020)

为什么要重试？

因为这类错误通常是“暂时性问题”，比如数据库连接不上，如果不重试，这条消息就会永久在业务端丢失。

##### 当发生错误的时候会怎么样？

1. Consumer signals failure

By returning `RECONSUME_LATER` , the consumer tells RockerMQ: "I couldnot process this message -- please retry it later."

2. Broker schedules a retry 

对于并发消费者，RocketMQ 会将失败的消息移至一个专用的重试主题（%RETRY%消费者组名称）。它会在退避延迟后重新投递消息，每次重试的延迟时间都会增加（10 秒、30 秒、1 分钟…… 最长可达 2 小时）。

3. Retry loop

消息会被反复重新投递，直到满足以下两个条件之一：

- 消息被成功消费（CONSUME_SUCCESS），
- 或者重试次数超过最大重试次数（maxReconsumeTimes，默认为16次）

4. Dead‑Letter Queue (DLQ)

如果重试次数用尽，消息将被移至 %DLQ% 消费者组名称。除非手动处理，否则不会进一步重试。这使您可以单独检查或重新处理失败的消息。 

##### 推荐做法

为确保稳健处理，我们建议：

1. 调整消费者的重试次数，如果我们需要重试的次数多于或是少于默认值（约是 16 次），我们需要设置 `consumer.setMaxReconsumeTimes (...)`

2. 处理有害消息，对于死信队列（DLQ）中的消息实施处理 -- 或许我们可以记录它们，发出警报，或者插入一个特殊的表中，以便后续手动处理。

3. 使得数据库操作具有幂等性，由于重试可能会重新处理相同的消息，确保使用基于 msgId 的唯一键插入日志，并捕获 DuplicateKeyException（我们已经在这么做了）是一种可靠的方法。

#### 消费成功返回

```java
return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
```

表示本批消息已成功消费完，RocketMQ 不再重复投递。

## 完整代码

```java
package com.jmz.mq2data.mqclient;

import java.nio.charset.StandardCharsets;
import java.util.List;

import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;
import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.common.consumer.ConsumeFromWhere;
import org.apache.rocketmq.common.message.MessageExt;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.dao.DuplicateKeyException;
import org.springframework.stereotype.Component;

import com.alibaba.fastjson.JSON;
import com.alibaba.fastjson.JSONArray;
import com.alibaba.fastjson.JSONObject;
import com.jmz.mq2data.config.RocketMQConfig;
import com.jmz.mq2data.mapper.MqConsumeLogMapper;
import com.jmz.mq2data.model.MqConsumeLog;

@Component
public class Consumer {
    private static final Logger log = LoggerFactory.getLogger(Consumer.class);

    private DefaultMQPushConsumer consumer;
    private String consumerGroup = "apisix_group";

    @Autowired
    private MqConsumeLogMapper logMapper;

    public Consumer() throws MQClientException {
        consumer = new DefaultMQPushConsumer(consumerGroup);
        consumer.setNamesrvAddr(RocketMQConfig.NAME_SERVER);
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_TIMESTAMP);
        consumer.setConsumeTimestamp("20240101000000");

        log.info("RocketMQ 消费者初始化中...");
        log.info("NameServer地址: {}", RocketMQConfig.NAME_SERVER);
        log.info("消费者组: {}", consumerGroup);

        consumer.subscribe(RocketMQConfig.TOPIC, "*");

        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(
                List<MessageExt> msgs, ConsumeConcurrentlyContext context
            ) {
                for (MessageExt message : msgs) {
                    String msgId = message.getMsgId();
                    String body = new String(message.getBody(), StandardCharsets.UTF_8);

                    try {
                        // 1) 先解析最外层 APISIX 日志，支持数组或对象
                        Object parsed = JSON.parse(body);
                        JSONObject logJson = null;

                        if (parsed instanceof JSONArray) {
                            JSONArray arr = (JSONArray) parsed;
                            if (arr.isEmpty()) {
                                log.warn("收到空数组日志，msgId={}", msgId);
                                continue;
                            }
                            logJson = arr.getJSONObject(0);
                        } else if (parsed instanceof JSONObject) {
                            logJson = (JSONObject) parsed;
                        } else {
                            log.error("日志格式不是 JSON 对象或数组，msgId={}, body={}", msgId, body);
                            continue;
                        }

                        // 2) 拆出路由 ID
                        String routeId = logJson.getString("route_id");

                        // 3) 拆出 APISIX response.body（它本身是字符串）
                        JSONObject responseJson = logJson.getJSONObject("response");
                        String responseBodyStr = responseJson != null
                            ? responseJson.getString("body")
                            : null;

                        // 4) 解析 OpenAI usage，可能为 null
                        Integer promptTokens    = null;
                        Integer completionTokens= null;
                        Integer totalTokens     = null;
                        if (responseBodyStr != null) {
                            JSONObject aiJson = JSON.parseObject(responseBodyStr);
                            JSONObject usage  = aiJson.getJSONObject("usage");
                            if (usage != null) {
                                promptTokens     = usage.getInteger("prompt_tokens");
                                completionTokens = usage.getInteger("completion_tokens");
                                totalTokens      = usage.getInteger("total_tokens");
                            }
                        }

                        // 5) 填充实体并入库
                        MqConsumeLog logEntity = new MqConsumeLog();
                        logEntity.setMsgId(msgId);
                        logEntity.setTopic(message.getTopic());
                        logEntity.setTags(message.getTags());
                        logEntity.setMessageKeys(message.getKeys());
                        logEntity.setBody(body);
                        logEntity.setRouteId(routeId);
                        logEntity.setPromptTokens(promptTokens);
                        logEntity.setCompletionTokens(completionTokens);
                        logEntity.setTotalTokens(totalTokens);

                        logMapper.insert(logEntity);
                        log.info("消息 [{}] 已写入数据库", msgId);
                    } catch (DuplicateKeyException e) {
                        log.warn("检测到重复消息 [{}]，已跳过", msgId);
                    } catch (Exception e) {
                        log.error("写库异常，msgId={}，稍后重试", msgId, e);
                        return ConsumeConcurrentlyStatus.RECONSUME_LATER;
                    }
                }

                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });

        try {
            consumer.start();
            log.info("RocketMQ 消费者启动成功！");
        } catch (MQClientException e) {
            log.error("消费者启动失败：{}", e.getErrorMessage(), e);
            throw e;
        }
    }
}
```

## 改进版本（遇到问题的时候回来看看这里）

上面的代码肯定是可以跑通的，但是存在一些问题，一些不符合最佳实践的做法：

#### APISIX 插件注册部分

单纯使用全局注册的方式太粗暴了。APISIX 插件有执行顺序（由 `priority` 决定），全局规则和路由规则共存时要注意冲突和覆盖。

#### RocketMQ-Logger 插件配置

1. **配置项不全**

    - 只列了最基础的 `nameserver_list`、`topic`、`include_req|resp_body`，缺少：
        - `producer_group`（指定 Producer Group）
        - `retry_times`、`send_timeout_ms`、`enable_msg_batch` 等可调节性能和可靠性的参数

2. **性能与可靠性考量**

    - 如果每次都同步发送（默认 `sync=true`），对网关吞吐有较大影响
    - 批量发送（`enable_msg_batch=true`）可大幅度减少网络开销

**改进建议**

- 建议根据流量峰值调优：
    - `enable_msg_batch: true`、`batch_max_size`、`batch_max_bytes`
    - `retry_times` （失败重试次数）、`send_timeout_ms`
- 生产环境中，务必多配置几个 `nameserver`，并准备好 `access_key`/`secret_key` 以便未来启用鉴权

#### Spring Boot 消费者代码

1. **与 rocketmq-spring-boot-starter 整合不一致**

	- 我们引入了 Starter，却又手动 new DefaultMQPushConsumer，未利用 Spring 注解方式（@RocketMQMessageListener、@RocketMQTransactionListener）

2. **消费并发与批量大小未配置**

- 默认 `consumeMessageBatchMaxSize=1`、线程池大小默认 20；如流量大需显式调优

**改进建议**

```java
@Service
@RocketMQMessageListener(topic = "${rocketmq.topic}", consumerGroup = "${rocketmq.consumer.group}")
public class ApisixLogConsumer implements RocketMQListener<String> { … }
```

利用 Starter 自动注入 `DefaultMQPushConsumer`，并从 `application.yml` 配置中读取参数。

#### 幂等性与异常处理

**偏差／遗漏**

1. **基于 `msgId` 的幂等**

    - `msgId` 虽全局唯一，但仅由 Broker 生成，无法反映业务侧“重复请求”
    - 如果需要严格业务层面去重，**应使用** `message.getKeys()`＋业务 `OrderId`、`UserId` 等做幂等

2. **批量消费失败回滚粒度**

    - 并发模式下，若一条消息处理抛出 `Exception`，整个批次会重试，导致已成功的消息被重复消费

**改进建议**

- **更可靠的幂等方案**：在消息发送端先 `producer.setKeys(bizId)`，消费者用 `keys` 作为唯一索引

- **细粒度失败处理**：

    - 将批量拆成单条处理，或者在捕获 `Exception` 时，先 log 丢到死信队列，然后对剩余消息继续返回 `CONSUME_SUCCESS`
    - 或升级到 RocketMQ 事务消息，根据业务结果再提交/回滚

